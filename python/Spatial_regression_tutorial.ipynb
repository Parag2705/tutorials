{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory to Spatial Regression in Python\n",
    "Author: Zach Schira\n",
    "\n",
    "Regression analysis allows you to model and predict some process based on its relationship to a specific dependent variable or variables. Often times, however, a standard regression model is insufficient for modeling data with a spatial dependency. This happens when the data is spatially autocorrelated. In these cases, you may want to instead use a spatial regression model.\n",
    "\n",
    "Spatial regression analysis allows you to encorporate spatial dependencies into your model. This tutorial will outline how to use the [PySAL](https://pypi.python.org/pypi/PySAL) Python package to use these spatial regression methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Perform ordinary linear regression analysis\n",
    "- Find spatial Autocorrelation of dataset\n",
    "- Perform spatial regression analysis\n",
    "\n",
    "## Dependencies\n",
    "- PySAL\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pysal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pysal\n",
    "import numpy as np\n",
    "from pysal.spreg import ols\n",
    "from pysal.spreg import ml_error\n",
    "from pysal.spreg import ml_lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pysal package contains many sample data files that can be used to demonstrate the package's abilities. For this example we will be analyzing Columbus home values with relation to income and crime by neighborhood. First we will run an [ordinary least squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) linear regression model to analyze the relationship between these variables.\n",
    "\n",
    "This first section of code will read in the home values (dependent variable) into an array `y` and the income and crime values (independent variables) into a two dimmensional array `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.892043999999999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pysal.open(pysal.examples.get_path(\"columbus.dbf\"),'r')\n",
    "y = np.array(f.by_col['HOVAL'])\n",
    "y.shape = (len(y),1)\n",
    "X= []\n",
    "X.append(f.by_col['INC'])\n",
    "X.append(f.by_col['CRIME'])\n",
    "X = np.array(X).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have stored the values we are analyzing we can perform our least squares test to determine dependency. This is done with the [pysal.spreg](http://pysal.readthedocs.io/en/v1.11.0/library/spreg/index.html) module. Our instance of `OLS`, named `ls`, has many useful tools for reviewing the results of our test. In this case, we will use `ls.summary` to obtain of full summary of the results, but for more specific results you can look at some of the other options on the `pysal.spreg` page linked above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: ORDINARY LEAST SQUARES\n",
      "-----------------------------------------\n",
      "Data set            :    Columbus\n",
      "Weights matrix      :        None\n",
      "Dependent Variable  :    home val                Number of Observations:          49\n",
      "Mean dependent var  :     38.4362                Number of Variables   :           3\n",
      "S.D. dependent var  :     18.4661                Degrees of Freedom    :          46\n",
      "R-squared           :      0.3495\n",
      "Adjusted R-squared  :      0.3212\n",
      "Sum squared residual:   10647.015                F-statistic           :     12.3582\n",
      "Sigma-square        :     231.457                Prob(F-statistic)     :   5.064e-05\n",
      "S.E. of regression  :      15.214                Log likelihood        :    -201.368\n",
      "Sigma-square ML     :     217.286                Akaike info criterion :     408.735\n",
      "S.E of regression ML:     14.7406                Schwarz criterion     :     414.411\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     t-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      46.4281827      13.1917570       3.5194844       0.0009867\n",
      "              Income       0.6289840       0.5359104       1.1736736       0.2465669\n",
      "               Crime      -0.4848885       0.1826729      -2.6544086       0.0108745\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "REGRESSION DIAGNOSTICS\n",
      "MULTICOLLINEARITY CONDITION NUMBER           12.538\n",
      "\n",
      "TEST ON NORMALITY OF ERRORS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Jarque-Bera                       2          39.706           0.0000\n",
      "\n",
      "DIAGNOSTICS FOR HETEROSKEDASTICITY\n",
      "RANDOM COEFFICIENTS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Breusch-Pagan test                2           5.767           0.0559\n",
      "Koenker-Bassett test              2           2.270           0.3214\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "ls = ols.OLS(y, X, name_y = 'home val', name_x = ['Income', 'Crime'], name_ds = 'Columbus')\n",
    "print(ls.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these results, we see the [sum squared residuals](https://en.wikipedia.org/wiki/Residual_sum_of_squares) is quite high, so we want a better model to fit our data.\n",
    "\n",
    "Now we will check whether or not there is a spacial dependency in this data using a [Moran's I](https://en.wikipedia.org/wiki/Moran%27s_I) test. Our first step in that process is to create a spatial weights matrix. PySAL's example data has a GAL file that we can read in directly to create this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = pysal.open(pysal.examples.get_path(\"columbus.gal\")).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our instance of Moran's using the data and the weights matrix. Looking at these results, we see that our observed value for I is much higher than the value we would expect if there was no spatial dependeny. As you would expect, this leads to a very low p-value, which allows us to assume that there is spatial dependency in these home values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed I: 0.180093114317 \n",
      "Expected I: -0.020833333333333332 \n",
      "   p-value: 0.0149554171455\n"
     ]
    }
   ],
   "source": [
    "mi = pysal.Moran(y, w, two_tailed=False)\n",
    "print('Observed I:', mi.I, '\\nExpected I:', mi.EI, '\\n   p-value:', mi.p_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found that there is spatial autocorrelation in this data, we can use a spatial regression model to see if that better fits our data. \n",
    "\n",
    "The `spreg` module has several different functions for creating a spatial regression model. In this example, we will use a spatial error model, but the implementation of a spatial lag model is almost identical. \n",
    "\n",
    "To compare our spatial regression model to our original linear regression model we can use the [Akaike info criterion(AIC)](https://en.wikipedia.org/wiki/Akaike_information_criterion#How_to_apply_AIC_in_practice). This value is a way to qualitatively compare the amount of information lost in a predictive model. The lower the AIC, the better the model. As you can see in the following output, the AIC for the spatial error model is lower than that of the original OLS model, meaning we have created a model that better fits our data using these spatial regression techniques.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: MAXIMUM LIKELIHOOD SPATIAL ERROR (METHOD = FULL)\n",
      "-------------------------------------------------------------------\n",
      "Data set            :    columbus\n",
      "Weights matrix      :columbus.gal\n",
      "Dependent Variable  :  home value                Number of Observations:          49\n",
      "Mean dependent var  :     38.4362                Number of Variables   :           3\n",
      "S.D. dependent var  :     18.4661                Degrees of Freedom    :          46\n",
      "Pseudo R-squared    :      0.3495\n",
      "Sigma-square ML     :     197.314                Log likelihood        :    -199.769\n",
      "S.E of regression   :      14.047                Akaike info criterion :     405.537\n",
      "                                                 Schwarz criterion     :     411.213\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     z-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      47.8090727      12.3906790       3.8584708       0.0001141\n",
      "              income       0.7213778       0.5029284       1.4343549       0.1514710\n",
      "               crime      -0.5576102       0.1788127      -3.1184037       0.0018183\n",
      "              lambda       0.3578233       0.1705868       2.0976021       0.0359403\n",
      "------------------------------------------------------------------------------------\n",
      "================================ END OF REPORT =====================================\n",
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: MAXIMUM LIKELIHOOD SPATIAL LAG (METHOD = FULL)\n",
      "-----------------------------------------------------------------\n",
      "Data set            :    columbus\n",
      "Weights matrix      :columbus.gal\n",
      "Dependent Variable  :  home value                Number of Observations:          49\n",
      "Mean dependent var  :     38.4362                Number of Variables   :           4\n",
      "S.D. dependent var  :     18.4661                Degrees of Freedom    :          45\n",
      "Pseudo R-squared    :      0.3668\n",
      "Spatial Pseudo R-squared:  0.3315\n",
      "Sigma-square ML     :     211.532                Log likelihood        :    -200.880\n",
      "S.E of regression   :      14.544                Akaike info criterion :     409.760\n",
      "                                                 Schwarz criterion     :     417.328\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     z-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      39.6683230      14.3249301       2.7691809       0.0056197\n",
      "              income       0.5793246       0.5189236       1.1163967       0.2642524\n",
      "               crime      -0.4635396       0.1800053      -2.5751442       0.0100198\n",
      "        W_home value       0.1748474       0.1669349       1.0473987       0.2949157\n",
      "------------------------------------------------------------------------------------\n",
      "================================ END OF REPORT =====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zach\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:596: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  \"defaulting to absolute tolerance.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "spat_err = ml_error.ML_Error(y, X, w, name_y='home value', name_x=['income','crime'], name_w='columbus.gal', name_ds='columbus')\n",
    "print(spat_err.summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
