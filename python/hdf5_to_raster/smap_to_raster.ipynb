{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 to Raster Tutorial with Python\n",
    "\n",
    "## About\n",
    "\n",
    "The National Snow and Ice Data Center hosts soil moisture data (from the NASA Soil Moisture Active Passive project, described [here](https://nsidc.org/data/smap), and hereafter referred to as SMAP) which is provided in .h5 format. HDF5 is a \"hierarchical\" data format, with multiple groups and datasets (further explained in Step 2) which are useful for storing and organizing large amounts of data. While this format is great for the large amount of data being collected, we often want to utilize a single dataset within the file. \n",
    "\n",
    "This tutorial demonstrates how to access SMAP data, and how to generate raster output from an HDF5 file. A raster is a two dimensional array, with each element in the array containing a specific value. In this case, the two dimensions correspond to longitude and latitude, and the elements or values represent soil moisture.\n",
    "    \n",
    "## Objectives\n",
    "\n",
    "1. Read in SMAP data file (in .h5 format)\n",
    "2. Extract specified data\n",
    "3. Create a raster object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "This tutorial requires h5py, gdal, and numpy. Ensure that you already have python and pip installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): h5py in /Users/majo3748/anaconda/envs/py27/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.6.1 in /Users/majo3748/anaconda/envs/py27/lib/python2.7/site-packages (from h5py)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in /Users/majo3748/anaconda/envs/py27/lib/python2.7/site-packages (from h5py)\n",
      "Requirement already satisfied (use --upgrade to upgrade): gdal==1.11.2 in /Users/majo3748/anaconda/envs/py27/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: numpy in /Users/majo3748/anaconda/envs/py27/lib/python2.7/site-packages\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py\n",
    "!pip install gdal==1.11.2\n",
    "!pip install numpy -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.11 |Anaconda 4.0.0 (x86_64)| (default, Dec  6 2015, 18:57:58) \n",
      "[GCC 4.2.1 (Apple Inc. build 5577)]\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import ftplib\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "\n",
    "#Useful information about the system being used\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Getting our data\n",
    "\n",
    "NOTE: The .h5 file is over 130 MB and may take some time to download. The download has completed when the asterisk in the 'In' parameter has become a numeric value and there is output below the cell. The following code chunk pulls one SMAP data file from the NSIDC FTP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'221-You have transferred 139218579 bytes in 1 files.\\n221-Total traffic for this session was 139219588 bytes in 1 transfers.\\n221-Thank you for using the FTP service on ftphost.\\n221 Goodbye.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp = ftplib.FTP(\"n5eil01u.ecs.nsidc.org\")\n",
    "ftp.login()\n",
    "\n",
    "path = \"SAN/SMAP/SPL4SMGP.001/2015.03.31/\"\n",
    "ftp.cwd(path)\n",
    "\n",
    "filename = \"SMAP_L4_SM_gph_20150331T013000_Vb1010_001.h5\"\n",
    "ftp.retrbinary(\"RETR \" + filename, open(filename, \"wb\"). write)\n",
    "\n",
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Inspecting the contents of an HDF5 file\n",
    "\n",
    "HDF5 files consist of 'Groups' and 'Datasets'. Datasets are multidimensional arrays of a homogenous type, and Groups are a container structure which hold numerous datasets. Groups are analogous to directories on your local file system. For more details on the structure of HDF5 files, see [this tutorial from the NEON Data Skills site](http://neondataskills.org/HDF5/About), or refer to the [HDF5 home page](https://www.hdfgroup.org/HDF5/).\n",
    "\n",
    "The following chunk of code prints the datasets within the \"Geophysical_Data\" group. The file that we downloaded is called SMAP_L4_SM_gph_20150331T013000_Vb1010_001.h5. If you have another .h5 file, you can replace the value of `file_path`. If you wish to inspect another group, you can replace `which_group`. For interactive exploration of HDF5 file contents, try [HDFView](https://www.hdfgroup.org/products/java/hdfview/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'surface_pressure' u'heat_flux_ground' u'land_fraction_wilting'\n",
      " u'soil_temp_layer5' u'sm_rootzone' u'radiation_longwave_absorbed_flux'\n",
      " u'specific_humidity_lowatmmodlay' u'surface_temp' u'temp_lowatmmodlay'\n",
      " u'net_downward_longwave_flux' u'snow_mass'\n",
      " u'precipitation_total_surface_flux' u'sm_surface_wetness'\n",
      " u'sm_profile_wetness' u'snow_depth' u'height_lowatmmodlay'\n",
      " u'baseflow_flux' u'sm_profile_pctl' u'land_fraction_saturated'\n",
      " u'snowfall_surface_flux' u'land_fraction_unsaturated'\n",
      " u'sm_rootzone_wetness' u'leaf_area_index'\n",
      " u'radiation_shortwave_downward_flux' u'sm_surface' u'soil_temp_layer1'\n",
      " u'heat_flux_sensible' u'soil_temp_layer4' u'soil_temp_layer6'\n",
      " u'land_fraction_snow_covered' u'land_evapotranspiration_flux'\n",
      " u'vegetation_greenness_fraction' u'sm_profile' u'soil_temp_layer3'\n",
      " u'overland_runoff_flux' u'snow_melt_flux' u'heat_flux_latent'\n",
      " u'soil_water_infiltration_flux' u'windspeed_lowatmmodlay'\n",
      " u'sm_rootzone_pctl' u'net_downward_shortwave_flux' u'soil_temp_layer2']\n"
     ]
    }
   ],
   "source": [
    "file_path = 'SMAP_L4_SM_gph_20150331T013000_Vb1010_001.h5'\n",
    "h5file = h5py.File(file_path, 'r') \n",
    "\n",
    "which_group = 'Geophysical_Data'\n",
    "group = h5file.get(which_group)\n",
    "datasets = np.array(group)\n",
    "print datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in this array represents a different Dataset contained in the group `Geophysical_Data`. We will work with `sm_surface_wetness`, `soil_temp_layer2` in this tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Using our data to create a Raster\n",
    "\n",
    "Now that we've decided which group(s) and dataset(s) we wish to use we need to create a raster object from the data. Because we are interested in two different datasets, we will extract both and subsequently \"stack\" them on top of one another.\n",
    "\n",
    "The following code chunk defines a function `smap2raster`, which we use for the generation of rasters from specific datasets in the SMAP data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smap2raster(inputFile, group, dataset):\n",
    "    \"\"\"Converts SMAP data to a Raster object\n",
    "Input:  \n",
    "    inputFile - SMAP data file\n",
    "    group - The groupt containing the dataset we want to pull data from\n",
    "    dataset - Which specific dataset we want to pull data from\n",
    "Output: \n",
    "    A raster image in .tif format, saved to the current working directory\n",
    "    \"\"\"\n",
    "    #Read in the SMAP file in h5 format\n",
    "    h5File = h5py.File(inputFile, 'r')\n",
    "    \n",
    "    #Get the data from the specific group/dataset\n",
    "    data = h5File.get(group + '/' + dataset)\n",
    "    lat = h5File.get('cell_lat')\n",
    "    lon = h5File.get('cell_lon')\n",
    "    \n",
    "    #Convert this data into numpy arrays\n",
    "    np_data = np.array(data)\n",
    "    np_lat = np.array(lat)\n",
    "    np_lon = np.array(lon)\n",
    "    \n",
    "    #Get the spatial extents of the data\n",
    "    num_cols = float(np_data.shape[1])\n",
    "    num_rows = float(np_data.shape[0])\n",
    "    xmin = np_lon.min()\n",
    "    xmax = np_lon.max()\n",
    "    ymin = np_lat.min()\n",
    "    ymax = np_lat.max()\n",
    "    xres = (xmax - xmin)/num_cols\n",
    "    yres = (ymax - ymin)/num_rows\n",
    "    \n",
    "    #Set up the transformation necessary to create the raster\n",
    "    geotransform = (xmin, xres, 0, ymax, 0, -yres)\n",
    "    \n",
    "    #Create the raster object with the proper coordinate encoding and geographic transformation\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    raster = driver.Create(dataset+'Raster.tif', int(num_cols), int(num_rows), 1, gdal.GDT_Float32)\n",
    "    raster.SetGeoTransform(geotransform)\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(4326)\n",
    "    \n",
    "    #Export and write the data array to the raster\n",
    "    raster.SetProjection( srs.ExportToWkt() )\n",
    "    raster.GetRasterBand(1).WriteArray(np_data)\n",
    "    h5File.close()\n",
    "\n",
    "#Create an array of the datasets we want to use\n",
    "#Replace 'snow_mass' and 'snow_depth' with the datasets you want to use\n",
    "datasets = ['sm_surface_wetness', 'soil_temp_layer2']\n",
    "\n",
    "#Loop through the datasets and create individual rasters from them\n",
    "for i in range(0, len(datasets)):\n",
    "    smap2raster(file_path, which_group, datasets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Creating a Raster Stack\n",
    "\n",
    "After running the above code, we have individual raster images (.tif files); the number of which depends on the amount of datasets you used (in this example we used two). Now that we have these individual rasters, we want to merge or \"stack\" them on top of each other. GDAL has a python script which accomplishes just this. The result of running this will be a new .tif file called out.tif which is the merging or 'stacking' of the 2 rasters we created in Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gdal_merge.py', <httplib.HTTPMessage instance at 0x106546830>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download python helper script to create raster stacks\n",
    "pythonfileDL = urllib.URLopener()\n",
    "url = 'https://svn.osgeo.org/gdal/trunk/gdal/swig/python/scripts/gdal_merge.py'\n",
    "pythonfileDL.retrieve(url, 'gdal_merge.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create raster stacks\n",
    "%run gdal_merge.py sm_surface_wetnessRaster.tif soil_temp_layer2Raster.tif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
